{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":253861,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":217066,"modelId":238780}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoModel, AutoTokenizer\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:21:42.432727Z","iopub.execute_input":"2025-02-09T14:21:42.433008Z","iopub.status.idle":"2025-02-09T14:21:53.033910Z","shell.execute_reply.started":"2025-02-09T14:21:42.432975Z","shell.execute_reply":"2025-02-09T14:21:53.032744Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class PhoBERTMultiTaskModel(nn.Module):\n    def __init__(self, model_name, num_aspects):\n        super(PhoBERTMultiTaskModel, self).__init__()\n\n        self.bert = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n        self.hidden_size = self.bert.config.hidden_size * 4  # Concatenating last 4 layers\n        self.dropout = nn.Dropout(0.2)\n\n        # ✅ Binary aspect detection (present or not)\n        self.aspect_detectors = nn.ModuleList([\n            nn.Linear(self.hidden_size, 2) for _ in range(num_aspects)\n        ])\n\n        # ✅ Sentiment classification (4 classes)\n        self.aspect_classifiers = nn.ModuleList([\n            nn.Linear(self.hidden_size, 4) for _ in range(num_aspects)\n        ])\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_states = outputs.hidden_states\n        pooled_output = torch.cat([hidden_states[-i][:, 0, :] for i in range(1, 5)], dim=-1)\n        pooled_output = self.dropout(pooled_output)\n\n        # ✅ Aspect detection (Binary)\n        aspect_presence = [detector(pooled_output) for detector in self.aspect_detectors]\n        aspect_presence = torch.stack(aspect_presence, dim=1)  # (batch_size, num_aspects, 2)\n\n        # ✅ Sentiment classification (4 classes)\n        aspect_sentiment = [classifier(pooled_output) for classifier in self.aspect_classifiers]\n        aspect_sentiment = torch.stack(aspect_sentiment, dim=1)  # (batch_size, num_aspects, 4)\n\n        return aspect_presence, aspect_sentiment","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:21:53.035008Z","iopub.execute_input":"2025-02-09T14:21:53.035526Z","iopub.status.idle":"2025-02-09T14:21:53.043564Z","shell.execute_reply.started":"2025-02-09T14:21:53.035487Z","shell.execute_reply":"2025-02-09T14:21:53.042576Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel\n\n# Define model path\nmodel_path = \"/kaggle/input/phobert_multitask-v2/transformers/default/1/phobert_multitask-V2\"\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\n# Load fine-tuned model\nmodel = PhoBERTMultiTaskModel(model_name=\"vinai/phobert-base\", num_aspects=34)\n\n# ✅ Force loading on CPU to avoid NCCL issues\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.load_state_dict(torch.load(f\"{model_path}/pytorch_model.bin\", map_location=device))\nmodel.to(device)\nmodel.eval()  # Set to evaluation mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:25:05.207164Z","iopub.execute_input":"2025-02-09T14:25:05.207494Z","iopub.status.idle":"2025-02-09T14:25:29.241268Z","shell.execute_reply.started":"2025-02-09T14:25:05.207469Z","shell.execute_reply":"2025-02-09T14:25:29.239975Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"705477e7c4c0413497dec399308c04dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7e78f15a3894fe5890accc5d55648fa"}},"metadata":{}},{"name":"stderr","text":"<ipython-input-3-562b68f01bc8>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"{model_path}/pytorch_model.bin\", map_location=device))\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"PhoBERTMultiTaskModel(\n  (bert): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.2, inplace=False)\n  (aspect_detectors): ModuleList(\n    (0-33): 34 x Linear(in_features=3072, out_features=2, bias=True)\n  )\n  (aspect_classifiers): ModuleList(\n    (0-33): 34 x Linear(in_features=3072, out_features=4, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"label_keys = [\n    \"FACILITIES#CLEANLINESS\", \"FACILITIES#DESIGN&FEATURES\", \"FACILITIES#MISCELLANEOUS\", \"FACILITIES#QUALITY\",\n    \"FOOD&DRINKS#PRICES\", \"FOOD&DRINKS#STYLE&OPTIONS\", \"HOTEL#COMFORT\", \"HOTEL#GENERAL\", \"HOTEL#PRICES\",\n    \"LOCATION#GENERAL\", \"ROOMS#COMFORT\", \"ROOMS#MISCELLANEOUS\", \"ROOMS#PRICES\", \"ROOM_AMENITIES#CLEANLINESS\",\n    \"ROOM_AMENITIES#GENERAL\", \"ROOM_AMENITIES#MISCELLANEOUS\", \"SERVICE#GENERAL\"\n]  # Ensure all aspects from training are listed\n\ndef predict(text):\n    \"\"\"Tokenizes input text, runs inference, and returns predicted aspect presence & sentiment.\"\"\"\n\n    # ✅ Tokenize input text and move to the same device as the model\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n    inputs = {key: value.to(device) for key, value in inputs.items()}  # ✅ Move to correct device\n\n    if \"token_type_ids\" in inputs:\n        del inputs[\"token_type_ids\"]\n\n    # Run inference\n    with torch.no_grad():\n        aspect_preds, sentiment_preds = model(**inputs)  # ✅ Model outputs two predictions\n\n    # ✅ Convert logits to class predictions\n    aspect_probs = torch.sigmoid(aspect_preds)  # Convert logits to probabilities (binary classification)\n    aspect_predictions = (aspect_probs > 0.5).cpu().numpy().flatten().tolist()  # Convert to 0 or 1\n\n    sentiment_labels = torch.argmax(sentiment_preds, dim=-1).cpu().numpy().flatten().tolist()  # Convert logits to class indices\n\n    # ✅ Sentiment mapping\n    sentiment_map = {0: \"None\", 1: \"Positive\", 2: \"Negative\", 3: \"Neutral\"}\n\n    # ✅ Prepare output\n    predictions = {}\n    for aspect, aspect_present, sentiment in zip(label_keys, aspect_predictions, sentiment_labels):\n        if aspect_present == 1:  # ✅ Only include aspects that are detected\n            predictions[aspect] = sentiment_map[int(sentiment)]\n\n    return predictions  # ✅ Returns dictionary of detected aspects & their sentiment\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:28:00.061217Z","iopub.execute_input":"2025-02-09T14:28:00.061589Z","iopub.status.idle":"2025-02-09T14:28:00.069899Z","shell.execute_reply.started":"2025-02-09T14:28:00.061560Z","shell.execute_reply":"2025-02-09T14:28:00.068627Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"text = input()\nres = predict(text)\nres","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:38:34.930723Z","iopub.execute_input":"2025-02-09T14:38:34.931075Z","iopub.status.idle":"2025-02-09T14:38:36.286295Z","shell.execute_reply.started":"2025-02-09T14:38:34.931039Z","shell.execute_reply":"2025-02-09T14:38:36.285220Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":" khách_sạn khá sạch_sẽ nhân_viên nhiệt_tình thân_thiện gần biển phạm văn đồng có_thể đi bộ ra biển được wifi tốt giá giặt là khá rẻ điểm trừ là không có máy_sấy tóc trong phòng\n"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'FACILITIES#CLEANLINESS': 'None',\n 'FACILITIES#MISCELLANEOUS': 'None',\n 'FOOD&DRINKS#PRICES': 'None',\n 'HOTEL#COMFORT': 'Positive',\n 'HOTEL#PRICES': 'None',\n 'ROOMS#COMFORT': 'None',\n 'ROOM_AMENITIES#CLEANLINESS': 'None',\n 'ROOM_AMENITIES#GENERAL': 'None',\n 'SERVICE#GENERAL': 'Positive'}"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"# The End","metadata":{}}]}