{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"D:\\\\Github\\\\ABSA-Vietnamese\\\\dataset\\\\1-VLSP2018-SA-Hotel-train.csv\"\n",
    "VAL_PATH = \"D:\\\\Github\\\\ABSA-Vietnamese\\\\dataset\\\\2-VLSP2018-SA-Hotel-dev.csv\"\n",
    "TEST_PATH = \"D:\\\\Github\\\\ABSA-Vietnamese\\\\dataset\\\\3-VLSP2018-SA-Hotel-test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset('csv', data_files={'train': TRAIN_PATH, 'val': VAL_PATH, 'test': TEST_PATH})\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_datasets['train'].column_names), len(raw_datasets['val'].column_names), len(raw_datasets['test'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets['train'][1]['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(is_valid_vietnamese_word(\"h√≤a\"))  # True (valid sequence of vowels)\n",
    "print(is_valid_vietnamese_word(\"ho√†\"))  # False (incorrect sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(is_valid_vietnamese_word(\"h√≤a\"))  # True ‚úÖ (Correct placement on \"a\")\n",
    "print(is_valid_vietnamese_word(\"ho√†\"))  # False ‚ùå (Incorrect placement on \"o\")\n",
    "print(is_valid_vietnamese_word(\"qu·ªëc\"))  # True ‚úÖ (Correct placement on \"√¥\")\n",
    "print(is_valid_vietnamese_word(\"q∆∞·ªëc\"))  # False ‚ùå (No such Vietnamese word)\n",
    "print(is_valid_vietnamese_word(\"ƒëi·ªÅu\"))  # True ‚úÖ (Correct placement on \"√™\")\n",
    "print(is_valid_vietnamese_word(\"ƒë√¨√™u\"))  # False ‚ùå (Incorrect placement on \"√¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(standardize_word_typing(\"ho√†\"))  # Output: \"ho√†\" (corrects misplaced accent)\n",
    "print(standardize_word_typing(\"q√∫oc\"))  # Output: \"qu·ªëc\" (remains unchanged)\n",
    "print(standardize_word_typing(\"gi√°o\"))  # Output: \"gi√°o\" (remains unchanged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Acronym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"okie, mik r·∫•t th√≠ch sp n√†y, ship nhanh!\"\n",
    "print(normalize_acronym(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text6 = \"h√†ng ƒë·∫πp l·∫Øm ‚≠ê‚≠ê‚≠ê! ch·∫•t l∆∞·ª£ng perfect üòç\"\n",
    "print(normalize_acronym(text6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = \"thanks shop nha, hsd d√†i, h√†ng auth!\"\n",
    "print(normalize_acronym(text5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP 4: WORD SEGMENTATION   \n",
    "annotator = VnCoreNLP(\"VnCoreNLP/VnCoreNLP-1.1.1.jar\")\n",
    "\n",
    "def word_segmentation(text):\n",
    "    words = annotator.tokenize(text)\n",
    "    return ' '.join(word for word in flatten(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"T√¥i y√™u l·∫≠p tr√¨nh Python.\"\n",
    "print(word_segmentation(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"H·ªçc sinh ƒëi h·ªçc v·ªÅ nh√†.\"\n",
    "print(word_segmentation(text2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
